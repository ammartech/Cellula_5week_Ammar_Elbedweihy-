{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§© Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠ (Python) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LangGraph Ùˆ RAG\n",
    "\n",
    "Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙØªØ± (Notebook) ÙŠØ¨Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯Ù‹Ø§ Ø¨Ø±Ù…Ø¬ÙŠÙ‹Ø§ ÙƒØ§Ù…Ù„Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `LangGraph` Ùˆ RAG (Ù…Ø¹ `Groq` ÙˆÙ†Ù…ÙˆØ°Ø¬ Llama 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 â€“ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª (Task 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph langchain langchain_core langchain_openai langchain_community sentence-transformers chromadb langchain_groq -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ (Setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import TypedDict, List, Annotated\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "print(\"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¨Ù†Ø¬Ø§Ø­.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ø£Ù…Ø«Ù„Ø© Ø§Ù„ÙƒÙˆØ¯ (Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ø¯ÙŠÙ†Ø§)\n",
    "code_examples = [\n",
    "    {\n",
    "        \"id\": \"ex_001\",\n",
    "        \"topic\": \"list_comprehension\",\n",
    "        \"code\": \"squares = [x*x for x in range(10)]\",\n",
    "        \"description\": \"This is a list comprehension. It creates a list of squares for numbers 0 through 9.\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ex_002\",\n",
    "        \"topic\": \"dictionary_loop\",\n",
    "        \"code\": \"my_dict = {'a': 1, 'b': 2}\\nfor key, value in my_dict.items():\\n    print(f'Key: {key}, Value: {value}')\",\n",
    "        \"description\": \"This is how you loop through a dictionary's keys and values using .items().\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"ex_003\",\n",
    "        \"topic\": \"python_function\",\n",
    "        \"code\": \"def add_numbers(a, b):\\n    '''Adds two numbers together.'''\\n    return a + b\",\n",
    "        \"description\": \"A simple Python function to add two numbers. It uses a docstring for documentation.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¥Ù„Ù‰ \\\"Ù…Ø³ØªÙ†Ø¯Ø§Øª\\\" (Documents) Ù„Ù€ Chroma\n",
    "documents = []\n",
    "for i, example in enumerate(code_examples):\n",
    "    content = f\"Topic: {example['topic']}\\nDescription: {example['description']}\\nCode: {example['code']}\"\n",
    "    # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© (metadata) Ø¨Ø³ÙŠØ·Ø© (string, int, float)\n",
    "    metadata = {\"doc_id\": example['id'], \"topic\": example['topic']}\n",
    "    documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "# 3. Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù€ Embeddings\n",
    "embeddings_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Chroma (ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©)\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents,\n",
    "    embeddings_model,\n",
    "    collection_name=\"code_examples\"\n",
    ")\n",
    "\n",
    "# 5. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ Retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# --- Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù€ Retriever ---\n",
    "test_query = \"how to loop over a dictionary\"\n",
    "retrieved_docs = retriever.invoke(test_query)\n",
    "print(f\"--- Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù€ Retriever (Query: '{test_query}') ---\")\n",
    "print(f\"ØªÙ… Ø¬Ù„Ø¨ {len(retrieved_docs)} Ù…Ø³ØªÙ†Ø¯Ø§Øª.\")\n",
    "print(f\"Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø£ÙˆÙ„ (ID): {retrieved_docs[0].metadata['doc_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø­Ø§Ù„Ø© (Chat State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ (ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©)\n",
    "    messages: Annotated[list, lambda x, y: x + y]\n",
    "    \n",
    "    # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£Ø®ÙŠØ± Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…\n",
    "    user_query: str\n",
    "    \n",
    "    # Ø§Ù„Ù†ÙŠØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: 'generate_code' Ø£Ùˆ 'explain_code'\n",
    "    intent: str\n",
    "    \n",
    "    # Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© Ù…Ù† Ø§Ù„Ù€ RAG (ÙƒÙ†Øµ)\n",
    "    retrieved_examples: str\n",
    "    \n",
    "    # Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªÙ‚Ø¯ÙŠÙ…Ù‡ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…\n",
    "    final_response: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ LLM (Groq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ **Ø®Ø·ÙˆØ© Ù‡Ø§Ù…Ø©: Ø¥Ø¶Ø§ÙØ© Ù…ÙØªØ§Ø­ API**\n",
    "\n",
    "1. Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ [GroqCloud Console](https://console.groq.com/keys)\n",
    "2. Ø£Ù†Ø´Ø¦ Ø­Ø³Ø§Ø¨Ø§Ù‹ (Ù…Ø¬Ø§Ù†ÙŠ) ÙˆØ§Ù†Ø³Ø® Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API.\n",
    "3. Ø£Ù„ØµÙ‚Ù‡ ÙÙŠ Ø§Ù„Ø®Ù„ÙŠØ© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ù…Ø®ØµØµ (`\"gsk_YOUR_GROQ_API_KEY_HERE\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ LLM (Groq) ---\n",
    "\n",
    "# !! Ù‡Ø§Ù…: Ø¶Ø¹ Ù…ÙØªØ§Ø­ API Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ù‡Ù†Ø§\n",
    "os.environ[\"GROQ_API_KEY\"] = \"gsk_YOUR_GROQ_API_KEY_HERE\" \n",
    "\n",
    "try:\n",
    "    llm = ChatGroq(\n",
    "        model=\"llama3-70b-8192\",\n",
    "        temperature=0.1  # Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ø±Ø¯ÙˆØ¯ Ø¯Ù‚ÙŠÙ‚Ø© ÙˆÙ…ØªÙˆÙ‚Ø¹Ø©\n",
    "    )\n",
    "    print(\"LLM (Groq - Llama 3 70B) initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Groq LLM: {e}\")\n",
    "    print(\"---!!! PLEASE CHECK YOUR API KEY IN THE LINE ABOVE !!!---\")\n",
    "\n",
    "# --- 2. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø³Ù„Ø§Ø³Ù„ (Chains) Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ---\n",
    "\n",
    "# (1) Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙŠØ©\n",
    "intent_parser = JsonOutputParser()\n",
    "intent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert intent classifier.\n",
    "Respond with ONLY a JSON object containing one key: \"intent\".\n",
    "The value must be one of: 'generate_code' OR 'explain_code'.\n",
    "'generate_code': User wants a code snippet, to do something, or a \\\"how-to\\\".\n",
    "'explain_code': User wants an explanation, definition, or \\\"what is\\\".\n",
    "\"\"\"\n",
    "    ),\n",
    "    (\"human\", \"User Query: {query}\")\n",
    "])\n",
    "\n",
    "# .itemgetter(\"intent\") Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ù€ JSON\n",
    "intent_chain = intent_prompt | llm | intent_parser | itemgetter(\"intent\")\n",
    "\n",
    "\n",
    "# (2) Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù€ Generation\n",
    "gen_prompt_template = \"\"\"You are a master Python programmer.\n",
    "Use the retrieved context to generate a code snippet that answers the user's request.\n",
    "Provide only the code block, with minimal explanation.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "---\n",
    "User Request: {query}\n",
    "---\n",
    "Generated Code:\"\"\"\n",
    "gen_prompt = ChatPromptTemplate.from_template(gen_prompt_template)\n",
    "generation_chain = gen_prompt | llm | StrOutputParser()\n",
    "\n",
    "# (3) Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù€ Explanation\n",
    "exp_prompt_template = \"\"\"You are a helpful programming tutor.\n",
    "Use the retrieved context to clearly explain the concept requested by the user.\n",
    "Be concise and clear.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "---\n",
    "User Request: {query}\n",
    "---\n",
    "Explanation:\"\"\"\n",
    "exp_prompt = ChatPromptTemplate.from_template(exp_prompt_template)\n",
    "explanation_chain = exp_prompt | llm | StrOutputParser()\n",
    "\n",
    "print(\"All chains (Intent, Generation, Explanation) are built.\")\n",
    "\n",
    "# --- Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹ Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ù†ÙŠØ© ---\n",
    "# (This will only work if the API key is valid)\n",
    "try:\n",
    "    test_intent = intent_chain.invoke({\"query\": \"what is a dictionary?\"})\n",
    "    print(f\"Intent test ('what is a dictionary?'): {test_intent}\")\n",
    "    test_intent_2 = intent_chain.invoke({\"query\": \"write me a for loop\"})\n",
    "    print(f\"Intent test ('write me a for loop'): {test_intent_2}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nSkipping intent test (API key not valid yet): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 5: ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø¹Ù‚Ø¯ (Nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"\n",
    "    Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: ØªØ­Ø¯Ø¯ Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØªØ®Ø²Ù†Ù‡Ø§ ÙÙŠ Ø§Ù„Ø­Ø§Ù„Ø©.\n",
    "    \"\"\"\n",
    "    print(\"--- Node: classify_intent_node ---\")\n",
    "    user_query = state['user_query']\n",
    "    \n",
    "    # --- Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©) ---\n",
    "    intent = intent_chain.invoke({\"query\": user_query})\n",
    "    print(f\"Detected Intent: {intent}\")\n",
    "    \n",
    "    return {\"intent\": intent}\n",
    "\n",
    "def retrieve_examples_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"\n",
    "    Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: ØªØ³ØªØ®Ø¯Ù… Ø§Ù„Ù€ Retriever Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.\n",
    "    \"\"\"\n",
    "    print(\"--- Node: retrieve_examples_node ---\")\n",
    "    user_query = state['user_query']\n",
    "    \n",
    "    retrieved_docs = retriever.invoke(user_query)\n",
    "    \n",
    "    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© ÙƒÙ†Øµ ÙˆØ§Ø­Ø¯ (context)\n",
    "    context_str = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    return {\"retrieved_examples\": context_str}\n",
    "\n",
    "def generate_response_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"\n",
    "    Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø© (ÙˆØ§Ù„Ø£Ø®ÙŠØ±Ø©): ØªÙˆÙ„Ø¯ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†ÙŠØ© ÙˆØ§Ù„Ø³ÙŠØ§Ù‚.\n",
    "    \"\"\"\n",
    "    print(\"--- Node: generate_response_node ---\")\n",
    "    user_query = state['user_query']\n",
    "    intent = state['intent']\n",
    "    context = state['retrieved_examples']\n",
    "\n",
    "    if intent == \"generate_code\":\n",
    "        print(\">> Calling Generation Chain...\")\n",
    "        # --- Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©) ---\n",
    "        final_response = generation_chain.invoke({\"query\": user_query, \"context\": context})\n",
    "        \n",
    "    elif intent == \"explain_code\":\n",
    "        print(\">> Calling Explanation Chain...\")\n",
    "        # --- Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©) ---\n",
    "        final_response = explanation_chain.invoke({\"query\": user_query, \"context\": context})\n",
    "    else:\n",
    "        print(f\">> ERROR: Unknown intent '{intent}'\")\n",
    "        final_response = \"Sorry, I'm not sure how to handle that intent.\"\n",
    "        \n",
    "    return {\"final_response\": final_response, \"messages\": [AIMessage(content=final_response)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 6: Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø· (Build the Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø®Ø·Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (ChatState)\n",
    "workflow = StateGraph(ChatState)\n",
    "\n",
    "# 1. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù‚Ø¯\n",
    "workflow.add_node(\"classify_intent\", classify_intent_node)\n",
    "workflow.add_node(\"retrieve_examples\", retrieve_examples_node)\n",
    "workflow.add_node(\"generate_response\", generate_response_node)\n",
    "\n",
    "# 2. ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©\n",
    "workflow.set_entry_point(\"classify_intent\")\n",
    "\n",
    "# 3. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª (Edges)\n",
    "workflow.add_edge(\"classify_intent\", \"retrieve_examples\")\n",
    "workflow.add_edge(\"retrieve_examples\", \"generate_response\")\n",
    "workflow.add_edge(\"generate_response\", END)\n",
    "\n",
    "# 4. ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®Ø·Ø· (Compile)\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"Graph compiled successfully!\")\n",
    "\n",
    "# (Optional) Visualize the graph\n",
    "# Ù‡Ø°Ø§ ÙŠØªØ·Ù„Ø¨ ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù‚Ø¯ Ù„Ø§ ØªØ¹Ù…Ù„ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¹Ù„Ù‰ Colab Ø¨Ø³Ù‡ÙˆÙ„Ø©\n",
    "try:\n",
    "    !pip install pygraphviz -q\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(app.get_graph().draw_png()))\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not visualize graph (pygraphviz/Graphviz not installed or configured correctly): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 7: ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ (Run the Assistant)\n",
    "\n",
    "Ø§Ù„Ø¢Ù† Ø³Ù†Ø¬Ø±Ø¨ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù‚Ø¯ Ø£Ø¶ÙØª Ù…ÙØªØ§Ø­ API Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ Ø³ØªÙØ´Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ù„ÙŠØ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===== TEST 1: GENERATE CODE =====")\n",
    "query_1 = \"write me some code to loop a dictionary\"\n",
    "initial_state_1 = {\n",
    "    \"messages\": [HumanMessage(content=query_1)],\n",
    "    \"user_query\": query_1\n",
    "}\n",
    "\n",
    "try:\n",
    "    # .stream() ÙŠØªÙŠØ­ Ù„Ù†Ø§ Ø±Ø¤ÙŠØ© Ù…Ø®Ø±Ø¬Ø§Øª ÙƒÙ„ Ø®Ø·ÙˆØ©\n",
    "    for event in app.stream(initial_state_1):\n",
    "        print(event)\n",
    "        print(\"---\")\n",
    "\n",
    "    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©\n",
    "    final_state_1 = app.invoke(initial_state_1) \n",
    "    print(\"\\n=== FINAL RESPONSE (Test 1) ===\")\n",
    "    print(final_state_1['final_response'])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nTest failed. Did you add your Groq API key in Cell 5? Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n===== TEST 2: EXPLAIN CODE =====")\n",
    "query_2 = \"what is a list comprehension in python?\"\n",
    "initial_state_2 = {\n",
    "    \"messages\": [HumanMessage(content=query_2)],\n",
    "    \"user_query\": query_2\n",
    "}\n",
    "\n",
    "try:\n",
    "    final_state_2 = app.invoke(initial_state_2)\n",
    "    print(\"\\n=== FINAL RESPONSE (Test 2) ===\")\n",
    "    print(final_state_2['final_response'])\n",
    "except Exception as e:\n",
    "    print(f\"\\nTest failed. Did you add your Groq API key in Cell 5? Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø§Ù„Ø®Ø·ÙˆØ© 8: Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ (Evaluation and Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ‚ÙŠÙŠÙ… ØµØºÙŠØ±Ø©\n",
    "evaluation_dataset = [\n",
    "    {\n",
    "        \"query\": \"how do I write a python function?\",\n",
    "        \"expected_intent\": \"generate_code\",\n",
    "        \"expected_retrieval_id\": \"ex_003\" # Ù†ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„ Ø§Ù„Ø¯Ø§Ù„Ø©\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"explain how dictionaries work\",\n",
    "        \"expected_intent\": \"explain_code\",\n",
    "        \"expected_retrieval_id\": \"ex_002\" # Ù†ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"what is list comprehension\",\n",
    "        \"expected_intent\": \"explain_code\",\n",
    "        \"expected_retrieval_id\": \"ex_001\" # Ù†ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø«Ø§Ù„ List Comp\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"make me a list of squares\",\n",
    "        \"expected_intent\": \"generate_code\",\n",
    "        \"expected_retrieval_id\": \"ex_001\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Evaluation dataset created with {len(evaluation_dataset)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "results = []\n",
    "intent_correct_count = 0\n",
    "retrieval_hit_count = 0\n",
    "\n",
    "print(\"--- Running Evaluation ---\")\n",
    "\n",
    "try:\n",
    "    for i, item in enumerate(evaluation_dataset):\n",
    "        print(f\"Evaluating item {i+1}/{len(evaluation_dataset)}...\")\n",
    "        \n",
    "        query = item[\"query\"]\n",
    "        \n",
    "        # 1. ØªÙ‚ÙŠÙŠÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ÙŠØ© (Intent)\n",
    "        # (Ù†Ø³ØªØ¯Ø¹ÙŠ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)\n",
    "        detected_intent = intent_chain.invoke({\"query\": query})\n",
    "        \n",
    "        is_intent_correct = (detected_intent == item[\"expected_intent\"])\n",
    "        if is_intent_correct:\n",
    "            intent_correct_count += 1\n",
    "            \n",
    "        # 2. ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ (Retrieval)\n",
    "        # (Ù†Ø³ØªØ¯Ø¹ÙŠ Ø§Ù„Ù€ retriever Ù…Ø¨Ø§Ø´Ø±Ø©)\n",
    "        retrieved_docs = retriever.invoke(query)\n",
    "        retrieved_ids = [doc.metadata['doc_id'] for doc in retrieved_docs]\n",
    "        \n",
    "        # Hit Rate: Ù‡Ù„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ø¶Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©ØŸ\n",
    "        is_retrieval_hit = (item[\"expected_retrieval_id\"] in retrieved_ids)\n",
    "        if is_retrieval_hit:\n",
    "            retrieval_hit_count += 1\n",
    "            \n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"expected_intent\": item[\"expected_intent\"],\n",
    "            \"detected_intent\": detected_intent,\n",
    "            \"intent_correct\": is_intent_correct,\n",
    "            \"expected_retrieval\": item[\"expected_retrieval_id\"],\n",
    "            \"retrieved_ids\": retrieved_ids,\n",
    "            \"retrieval_hit\": is_retrieval_hit\n",
    "        })\n",
    "\n",
    "    print(\"--- Evaluation Complete ---\")\n",
    "\n",
    "    # 3. Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Metrics)\n",
    "    total_items = len(evaluation_dataset)\n",
    "\n",
    "    intent_accuracy = (intent_correct_count / total_items) * 100\n",
    "    retrieval_hit_rate = (retrieval_hit_count / total_items) * 100\n",
    "\n",
    "    print(f\"\\n===== ğŸ“Š Evaluation Metrics =====")\n",
    "    print(f\"Intent Accuracy:   {intent_accuracy:.2f}%\")\n",
    "    print(f\"Retrieval Hit Rate: {retrieval_hit_rate:.2f}%\")\n",
    "    print(\"==================================\\n\")\n",
    "\n",
    "    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© ÙÙŠ Ø¬Ø¯ÙˆÙ„\n",
    "    df_results = pd.DataFrame(results)\n",
    "    display(df_results)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nEvaluation failed. Did you add your Groq API key in Cell 5? Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LangGraph RAG Bot (Groq).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
